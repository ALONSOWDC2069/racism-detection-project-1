{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:25:48.850166Z",
     "iopub.status.busy": "2021-08-10T07:25:48.849741Z",
     "iopub.status.idle": "2021-08-10T07:26:02.057406Z",
     "shell.execute_reply": "2021-08-10T07:26:02.056396Z",
     "shell.execute_reply.started": "2021-08-10T07:25:48.850083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-for-tf2 in c:\\programdata\\anaconda3\\lib\\site-packages (0.14.9)\n",
      "Requirement already satisfied: params-flow>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert-for-tf2) (0.8.2)\n",
      "Requirement already satisfied: py-params>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from bert-for-tf2) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->params-flow>=0.8.0->bert-for-tf2) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:02.059517Z",
     "iopub.status.busy": "2021-08-10T07:26:02.059192Z",
     "iopub.status.idle": "2021-08-10T07:26:02.904752Z",
     "shell.execute_reply": "2021-08-10T07:26:02.903914Z",
     "shell.execute_reply.started": "2021-08-10T07:26:02.059478Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:02.908622Z",
     "iopub.status.busy": "2021-08-10T07:26:02.908348Z",
     "iopub.status.idle": "2021-08-10T07:26:08.596202Z",
     "shell.execute_reply": "2021-08-10T07:26:08.595304Z",
     "shell.execute_reply.started": "2021-08-10T07:26:02.908594Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "import bert \n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:08.598204Z",
     "iopub.status.busy": "2021-08-10T07:26:08.597861Z",
     "iopub.status.idle": "2021-08-10T07:26:10.266708Z",
     "shell.execute_reply": "2021-08-10T07:26:10.265788Z",
     "shell.execute_reply.started": "2021-08-10T07:26:08.598168Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_val = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.268634Z",
     "iopub.status.busy": "2021-08-10T07:26:10.268245Z",
     "iopub.status.idle": "2021-08-10T07:26:10.319505Z",
     "shell.execute_reply": "2021-08-10T07:26:10.318526Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.268591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.info())\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.321261Z",
     "iopub.status.busy": "2021-08-10T07:26:10.320872Z",
     "iopub.status.idle": "2021-08-10T07:26:10.348267Z",
     "shell.execute_reply": "2021-08-10T07:26:10.347315Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.321212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_val.info())\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=\"label\", data = df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.350427Z",
     "iopub.status.busy": "2021-08-10T07:26:10.349817Z",
     "iopub.status.idle": "2021-08-10T07:26:10.381411Z",
     "shell.execute_reply": "2021-08-10T07:26:10.380365Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.350380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.info())\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.386178Z",
     "iopub.status.busy": "2021-08-10T07:26:10.385737Z",
     "iopub.status.idle": "2021-08-10T07:26:10.393931Z",
     "shell.execute_reply": "2021-08-10T07:26:10.392336Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.386142Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred_proba):\n",
    "    print('ACCURACY_SCORE: ', round(accuracy_score(y_test, y_pred_proba >= 0.5), 4))\n",
    "    print('F1_SCORE: ', round(f1_score(y_test, y_pred_proba >= 0.5, average = \"macro\"), 4))\n",
    "    print('ROC_AUC_SCORE: ', round(roc_auc_score(y_test, y_pred_proba), 4))\n",
    "    print('CONFUSION_MATRIX:\\n', confusion_matrix(y_test, y_pred_proba >= 0.5),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:10.397065Z",
     "iopub.status.busy": "2021-08-10T07:26:10.396248Z",
     "iopub.status.idle": "2021-08-10T07:26:20.195952Z",
     "shell.execute_reply": "2021-08-10T07:26:20.194943Z",
     "shell.execute_reply.started": "2021-08-10T07:26:10.397026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removes Punctuations\n",
    "def remove_punctuations(data):\n",
    "    punct_tag=re.compile(r'[^\\w\\s]')\n",
    "    data=punct_tag.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes HTML syntaxes\n",
    "def remove_html(data):\n",
    "    html_tag=re.compile(r'<.*?>')\n",
    "    data=html_tag.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes URL data\n",
    "def remove_url(data):\n",
    "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
    "    data=url_clean.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes Emojis\n",
    "def remove_emoji(data):\n",
    "    emoji_clean= re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    data=emoji_clean.sub(r'',data)\n",
    "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
    "    data=url_clean.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_punctuations(z))\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_html(z))\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_url(z))\n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_emoji(z))\n",
    "\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_punctuations(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_html(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_url(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_emoji(z))\n",
    "\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_punctuations(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_html(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_url(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_emoji(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:20.198062Z",
     "iopub.status.busy": "2021-08-10T07:26:20.197659Z",
     "iopub.status.idle": "2021-08-10T07:26:29.894639Z",
     "shell.execute_reply": "2021-08-10T07:26:29.893810Z",
     "shell.execute_reply.started": "2021-08-10T07:26:20.198019Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_abb(data):\n",
    "    data = re.sub(r\"he's\", \"he is\", data)\n",
    "    data = re.sub(r\"there's\", \"there is\", data)\n",
    "    data = re.sub(r\"We're\", \"We are\", data)\n",
    "    data = re.sub(r\"That's\", \"That is\", data)\n",
    "    data = re.sub(r\"won't\", \"will not\", data)\n",
    "    data = re.sub(r\"they're\", \"they are\", data)\n",
    "    data = re.sub(r\"Can't\", \"Cannot\", data)\n",
    "    data = re.sub(r\"wasn't\", \"was not\", data)\n",
    "    data = re.sub(r\"don\\x89Ûªt\", \"do not\", data)\n",
    "    data= re.sub(r\"aren't\", \"are not\", data)\n",
    "    data = re.sub(r\"isn't\", \"is not\", data)\n",
    "    data = re.sub(r\"What's\", \"What is\", data)\n",
    "    data = re.sub(r\"haven't\", \"have not\", data)\n",
    "    data = re.sub(r\"hasn't\", \"has not\", data)\n",
    "    data = re.sub(r\"There's\", \"There is\", data)\n",
    "    data = re.sub(r\"He's\", \"He is\", data)\n",
    "    data = re.sub(r\"It's\", \"It is\", data)\n",
    "    data = re.sub(r\"You're\", \"You are\", data)\n",
    "    data = re.sub(r\"I'M\", \"I am\", data)\n",
    "    data = re.sub(r\"shouldn't\", \"should not\", data)\n",
    "    data = re.sub(r\"wouldn't\", \"would not\", data)\n",
    "    data = re.sub(r\"i'm\", \"I am\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªm\", \"I am\", data)\n",
    "    data = re.sub(r\"I'm\", \"I am\", data)\n",
    "    data = re.sub(r\"Isn't\", \"is not\", data)\n",
    "    data = re.sub(r\"Here's\", \"Here is\", data)\n",
    "    data = re.sub(r\"you've\", \"you have\", data)\n",
    "    data = re.sub(r\"you\\x89Ûªve\", \"you have\", data)\n",
    "    data = re.sub(r\"we're\", \"we are\", data)\n",
    "    data = re.sub(r\"what's\", \"what is\", data)\n",
    "    data = re.sub(r\"couldn't\", \"could not\", data)\n",
    "    data = re.sub(r\"we've\", \"we have\", data)\n",
    "    data = re.sub(r\"it\\x89Ûªs\", \"it is\", data)\n",
    "    data = re.sub(r\"doesn\\x89Ûªt\", \"does not\", data)\n",
    "    data = re.sub(r\"It\\x89Ûªs\", \"It is\", data)\n",
    "    data = re.sub(r\"Here\\x89Ûªs\", \"Here is\", data)\n",
    "    data = re.sub(r\"who's\", \"who is\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªve\", \"I have\", data)\n",
    "    data = re.sub(r\"y'all\", \"you all\", data)\n",
    "    data = re.sub(r\"can\\x89Ûªt\", \"cannot\", data)\n",
    "    data = re.sub(r\"would've\", \"would have\", data)\n",
    "    data = re.sub(r\"it'll\", \"it will\", data)\n",
    "    data = re.sub(r\"we'll\", \"we will\", data)\n",
    "    data = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", data)\n",
    "    data = re.sub(r\"We've\", \"We have\", data)\n",
    "    data = re.sub(r\"he'll\", \"he will\", data)\n",
    "    data = re.sub(r\"Y'all\", \"You all\", data)\n",
    "    data = re.sub(r\"Weren't\", \"Were not\", data)\n",
    "    data = re.sub(r\"Didn't\", \"Did not\", data)\n",
    "    data = re.sub(r\"they'll\", \"they will\", data)\n",
    "    data = re.sub(r\"they'd\", \"they would\", data)\n",
    "    data = re.sub(r\"DON'T\", \"DO NOT\", data)\n",
    "    data = re.sub(r\"That\\x89Ûªs\", \"That is\", data)\n",
    "    data = re.sub(r\"they've\", \"they have\", data)\n",
    "    data = re.sub(r\"i'd\", \"I would\", data)\n",
    "    data = re.sub(r\"should've\", \"should have\", data)\n",
    "    data = re.sub(r\"You\\x89Ûªre\", \"You are\", data)\n",
    "    data = re.sub(r\"where's\", \"where is\", data)\n",
    "    data = re.sub(r\"Don\\x89Ûªt\", \"Do not\", data)\n",
    "    data = re.sub(r\"we'd\", \"we would\", data)\n",
    "    data = re.sub(r\"i'll\", \"I will\", data)\n",
    "    data = re.sub(r\"weren't\", \"were not\", data)\n",
    "    data = re.sub(r\"They're\", \"They are\", data)\n",
    "    data = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", data)\n",
    "    data = re.sub(r\"you\\x89Ûªll\", \"you will\", data)\n",
    "    data = re.sub(r\"I\\x89Ûªd\", \"I would\", data)\n",
    "    data = re.sub(r\"let's\", \"let us\", data)\n",
    "    data = re.sub(r\"it's\", \"it is\", data)\n",
    "    data = re.sub(r\"can't\", \"cannot\", data)\n",
    "    data = re.sub(r\"don't\", \"do not\", data)\n",
    "    data = re.sub(r\"you're\", \"you are\", data)\n",
    "    data = re.sub(r\"i've\", \"I have\", data)\n",
    "    data = re.sub(r\"that's\", \"that is\", data)\n",
    "    data = re.sub(r\"i'll\", \"I will\", data)\n",
    "    data = re.sub(r\"doesn't\", \"does not\",data)\n",
    "    data = re.sub(r\"i'd\", \"I would\", data)\n",
    "    data = re.sub(r\"didn't\", \"did not\", data)\n",
    "    data = re.sub(r\"ain't\", \"am not\", data)\n",
    "    data = re.sub(r\"you'll\", \"you will\", data)\n",
    "    data = re.sub(r\"I've\", \"I have\", data)\n",
    "    data = re.sub(r\"Don't\", \"do not\", data)\n",
    "    data = re.sub(r\"I'll\", \"I will\", data)\n",
    "    data = re.sub(r\"I'd\", \"I would\", data)\n",
    "    data = re.sub(r\"Let's\", \"Let us\", data)\n",
    "    data = re.sub(r\"you'd\", \"You would\", data)\n",
    "    data = re.sub(r\"It's\", \"It is\", data)\n",
    "    data = re.sub(r\"Ain't\", \"am not\", data)\n",
    "    data = re.sub(r\"Haven't\", \"Have not\", data)\n",
    "    data = re.sub(r\"Could've\", \"Could have\", data)\n",
    "    data = re.sub(r\"youve\", \"you have\", data)  \n",
    "    data = re.sub(r\"donå«t\", \"do not\", data)  \n",
    "    return data\n",
    "    \n",
    "df_train['tweet'] = df_train['tweet'].apply(lambda z: remove_abb(z))\n",
    "df_val['tweet'] = df_val['tweet'].apply(lambda z: remove_abb(z))\n",
    "df_test['tweet'] = df_test['tweet'].apply(lambda z: remove_abb(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.896358Z",
     "iopub.status.busy": "2021-08-10T07:26:29.896023Z",
     "iopub.status.idle": "2021-08-10T07:26:29.909742Z",
     "shell.execute_reply": "2021-08-10T07:26:29.908897Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.896323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 3)\n",
      "   id  label                                              tweet\n",
      "0   1      0   user when a father is dysfunctional and is so...\n",
      "1   2      0  user user thanks for lyft credit i cant use ca...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  model   i love u take with u all the time in u...\n",
      "4   5      0               factsguide society now    motivation\n",
      "(31962, 3)\n",
      "   id  label                                              tweet\n",
      "0   1      0   user when a father is dysfunctional and is so...\n",
      "1   2      0  user user thanks for lyft credit i cant use ca...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  model   i love u take with u all the time in u...\n",
      "4   5      0               factsguide society now    motivation\n",
      "(31962, 3)\n",
      "   id  label                                              tweet\n",
      "0   1      0   user when a father is dysfunctional and is so...\n",
      "1   2      0  user user thanks for lyft credit i cant use ca...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  model   i love u take with u all the time in u...\n",
      "4   5      0               factsguide society now    motivation\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_train.head(5))\n",
    "print(df_val.shape)\n",
    "print(df_val.head(5))\n",
    "print(df_test.shape)\n",
    "print(df_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.911486Z",
     "iopub.status.busy": "2021-08-10T07:26:29.911083Z",
     "iopub.status.idle": "2021-08-10T07:26:29.923672Z",
     "shell.execute_reply": "2021-08-10T07:26:29.922301Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.911449Z"
    }
   },
   "outputs": [],
   "source": [
    "class IntentDetectionData:\n",
    "    DATA_COLUMN,  LABEL_COLUMN  = \"tweet\",\"label\"\n",
    "\n",
    "    def __init__(self, train, val, test, tokenizer: FullTokenizer, classes, max_seq_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = 0\n",
    "        self.classes = classes\n",
    "\n",
    "        ((self.train_x, self.train_y), (self.val_x, self.val_y), (self.test_x, self.test_y)) = map(self._prepare, [train, val, test])\n",
    "\n",
    "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
    "        self.train_x, self.val_x, self.test_x = map(self._pad, [self.train_x, self.val_x, self.test_x])\n",
    "\n",
    "    def _prepare(self, df):\n",
    "        x, y = [], []\n",
    "    \n",
    "        for non, row in tqdm(df.iterrows()):\n",
    "            text, label =\\\n",
    "                row[IntentDetectionData.DATA_COLUMN], row[IntentDetectionData.LABEL_COLUMN]\n",
    "\n",
    "            tokens = self.tokenizer.tokenize(text)\n",
    "            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"] ## Tokens beigning and ending specified by separation of tokens.\n",
    "\n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens) ## Convert Tokens to IDs\n",
    "\n",
    "            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
    "\n",
    "            x.append(token_ids)\n",
    "            y.append(self.classes.index(label))\n",
    "\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def _pad(self, ids):\n",
    "        x = []\n",
    "        for input_ids in ids:\n",
    "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)] ## -2 as ignoring tokens provided by bert\n",
    "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids)) ## padding by zeros\n",
    "            x.append(np.array(input_ids))\n",
    "        \n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.937188Z",
     "iopub.status.busy": "2021-08-10T07:26:29.936788Z",
     "iopub.status.idle": "2021-08-10T07:26:29.944494Z",
     "shell.execute_reply": "2021-08-10T07:26:29.943377Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.937153Z"
    }
   },
   "outputs": [],
   "source": [
    "def CNN_V0(bert_output):\n",
    "    net = Conv1D(128, 7, activation='relu',padding='same')(bert_output)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(256, 5, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(512, 3, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(128, activation='relu')(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.946482Z",
     "iopub.status.busy": "2021-08-10T07:26:29.945943Z",
     "iopub.status.idle": "2021-08-10T07:26:29.955890Z",
     "shell.execute_reply": "2021-08-10T07:26:29.955048Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.946447Z"
    }
   },
   "outputs": [],
   "source": [
    "def BiLSTM_V0(bert_output):\n",
    "    net = Bidirectional(LSTM(units=32, return_sequences=True,))(bert_output)\n",
    "    net = GlobalAveragePooling1D()(net)\n",
    "    net = Dense(20, activation='relu')(net)\n",
    "    net = Dropout(rate=0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_V0(bert_output):\n",
    "    net = LSTM(units=32, return_sequences=True,)(bert_output)\n",
    "    net = GlobalAveragePooling1D()(net)\n",
    "    net = Dense(20, activation='relu')(net)\n",
    "    net = Dropout(rate=0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.957832Z",
     "iopub.status.busy": "2021-08-10T07:26:29.957381Z",
     "iopub.status.idle": "2021-08-10T07:26:29.966297Z",
     "shell.execute_reply": "2021-08-10T07:26:29.965406Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.957794Z"
    }
   },
   "outputs": [],
   "source": [
    "def CNN_LSTM_V0(bert_output):\n",
    "    net = Dropout(0.3)(bert_output)\n",
    "    net = Conv1D(200, 5, activation='relu')(net)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = LSTM(100)(net)\n",
    "    net = Dropout(0.3)(net)\n",
    "    net = Dense(16,activation='relu')(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.967965Z",
     "iopub.status.busy": "2021-08-10T07:26:29.967447Z",
     "iopub.status.idle": "2021-08-10T07:26:29.978780Z",
     "shell.execute_reply": "2021-08-10T07:26:29.977934Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.967923Z"
    }
   },
   "outputs": [],
   "source": [
    "def CNN_LSTM_V1(bert_output):\n",
    "\n",
    "    # channel 1\n",
    "    net = Conv1D(filters=128, kernel_size=3*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    a = LSTM(128)(net)\n",
    "\n",
    "    # channel 2\n",
    "    net = Conv1D(filters=128, kernel_size=5*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    b = LSTM(128)(net)\n",
    "\n",
    "    # channel 3\n",
    "    net = Conv1D(filters=128, kernel_size=7*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    c = LSTM(128)(net)\n",
    "\n",
    "    # channel 4\n",
    "    net = Conv1D(filters=128, kernel_size=9*32, activation='relu')(bert_output)\n",
    "    net = MaxPooling1D(pool_size=2)(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    d = LSTM(128)(net)\n",
    "\n",
    "    merged = concatenate([a,b,c,d])\n",
    "    dense = Dense(100, activation='relu')(merged)\n",
    "    drop = Dropout(0.2)(dense)\n",
    "    outputs = Dense(1, activation='sigmoid')(merged)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.980771Z",
     "iopub.status.busy": "2021-08-10T07:26:29.980351Z",
     "iopub.status.idle": "2021-08-10T07:26:29.996620Z",
     "shell.execute_reply": "2021-08-10T07:26:29.995824Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.980701Z"
    }
   },
   "outputs": [],
   "source": [
    "def LSTM_CNN_V0(bert_output):\n",
    "    net = Bidirectional(LSTM(128, return_sequences=True))(bert_output)\n",
    "    net = Conv1D(128, 7, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(256, 5, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Conv1D(512, 3, activation='relu',padding='same')(net)\n",
    "    net = MaxPooling1D()(net)\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(128, activation='relu')(net)\n",
    "    net = Dropout(0.5)(net)\n",
    "    outputs = Dense(1, activation='sigmoid', name='classifier')(net) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:29.998506Z",
     "iopub.status.busy": "2021-08-10T07:26:29.998053Z",
     "iopub.status.idle": "2021-08-10T07:26:30.008012Z",
     "shell.execute_reply": "2021-08-10T07:26:30.006950Z",
     "shell.execute_reply.started": "2021-08-10T07:26:29.998470Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(model_name, model_ver, max_seq_len, bert_checkpnt_file):\n",
    "\n",
    "    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "        bc = StockBertConfig.from_json_string(reader.read()) ## Reading bert config\n",
    "        bert_params = map_stock_config_to_params(bc) ## Mapping parameters \n",
    "        bert_params.adapter_size = None # Adapter size helps tune Bert model faster\n",
    "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "        \n",
    "    ## Creat dictionary\n",
    "    choose_model = {'CNN':{0: CNN_V0},\n",
    "                    'BiLSTM':{0: BiLSTM_V0},\n",
    "                    'LSTM':{0: LSTM_V0},\n",
    "                    'CNN+LSTM':{0: CNN_LSTM_V0, 1: CNN_LSTM_V1},\n",
    "                    'LSTM+CNN':{0: LSTM_CNN_V0},}\n",
    "    \n",
    "    ## Specifying input\n",
    "    input_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
    "    bert_output = bert(input_ids)\n",
    "        \n",
    "    outputs = choose_model[model_name][model_ver](bert_output)\n",
    "\n",
    "    model = keras.Model(input_ids, outputs)\n",
    "    model.build(input_shape=(None, max_seq_len))\n",
    "    load_stock_weights(bert, bert_checkpnt_file) ##Loading the weights from bert chckpoint file\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:30.009910Z",
     "iopub.status.busy": "2021-08-10T07:26:30.009405Z",
     "iopub.status.idle": "2021-08-10T07:26:36.969127Z",
     "shell.execute_reply": "2021-08-10T07:26:36.968107Z",
     "shell.execute_reply.started": "2021-08-10T07:26:30.009874Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_model_name = \"uncased_L-12_H-768_A-12\"\n",
    "# uncased_L-4_H-512_A-8\n",
    "# uncased_L-12_H-768_A-12\n",
    "\n",
    "#!wget  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n",
    "#!unzip {bert_model_name}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:36.971183Z",
     "iopub.status.busy": "2021-08-10T07:26:36.970837Z",
     "iopub.status.idle": "2021-08-10T07:26:36.978593Z",
     "shell.execute_reply": "2021-08-10T07:26:36.977614Z",
     "shell.execute_reply.started": "2021-08-10T07:26:36.971143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./bert_model.ckpt\n",
      "./bert_config.json\n",
      "./vocab.txt\n"
     ]
    }
   ],
   "source": [
    "bert_model_path = \"./\"\n",
    "bert_checkpnt_file = os.path.join(bert_model_path, \"bert_model.ckpt\")\n",
    "bert_config_file = os.path.join(bert_model_path, \"bert_config.json\")\n",
    "bert_vocab_file = os.path.join(bert_model_path, \"vocab.txt\")\n",
    "print(bert_checkpnt_file)\n",
    "print(bert_config_file)\n",
    "print(bert_vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:36.980799Z",
     "iopub.status.busy": "2021-08-10T07:26:36.980145Z",
     "iopub.status.idle": "2021-08-10T07:26:37.101231Z",
     "shell.execute_reply": "2021-08-10T07:26:37.100256Z",
     "shell.execute_reply.started": "2021-08-10T07:26:36.980748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people', 'say', 'nothing', 'is', 'impossible', ',', 'but', 'i', 'do', 'nothing', 'everyday']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2111, 2360, 2498, 2003, 5263, 1010, 2021, 1045, 2079, 2498, 10126]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = FullTokenizer(vocab_file=bert_vocab_file)\n",
    "tokens = tokenizer.tokenize(\"People say nothing is impossible, but I do nothing everyday\")\n",
    "print(tokens)\n",
    "tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:26:37.105496Z",
     "iopub.status.busy": "2021-08-10T07:26:37.105152Z",
     "iopub.status.idle": "2021-08-10T07:31:20.236254Z",
     "shell.execute_reply": "2021-08-10T07:31:20.235183Z",
     "shell.execute_reply.started": "2021-08-10T07:26:37.105467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31962it [00:09, 3305.68it/s]\n",
      "31962it [00:09, 3549.45it/s]\n",
      "31962it [00:08, 3605.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "classes = [0, 1]\n",
    "max_seq_len = 72\n",
    "data = IntentDetectionData(df_train, df_val, df_test, tokenizer, classes, max_seq_len)\n",
    "print(data.max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN - NN with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:31:20.238316Z",
     "iopub.status.busy": "2021-08-10T07:31:20.237973Z",
     "iopub.status.idle": "2021-08-10T07:31:32.015735Z",
     "shell.execute_reply": "2021-08-10T07:31:32.014886Z",
     "shell.execute_reply.started": "2021-08-10T07:31:20.238278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 196 BERT weights from: ./bert_model.ckpt into <bert.model.BertModelLayer object at 0x00000255FF220220> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 72)]              0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 72, 768)           108890112 \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 72, 128)           688256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 36, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 36, 256)           164096    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 18, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 18, 512)           393728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 110,726,273\n",
      "Trainable params: 110,726,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CNN\"\n",
    "model_ver = 0\n",
    "LR = 2e-5\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = Adam(learning_rate=LR)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "model = create_model(model_name, model_ver, max_seq_len, bert_checkpnt_file)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T07:31:32.560934Z",
     "iopub.status.busy": "2021-08-10T07:31:32.560525Z",
     "iopub.status.idle": "2021-08-10T09:44:14.853488Z",
     "shell.execute_reply": "2021-08-10T09:44:14.852254Z",
     "shell.execute_reply.started": "2021-08-10T07:31:32.560892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with uncased_L-12_H-768_A-12_CNN_V0_72\n",
      "\n",
      "Epoch 1/2\n",
      "1998/1998 [==============================] - ETA: 0s - loss: 0.6938 - binary_accuracy: 0.9291\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.92985, saving model to [uncased_L-12_H-768_A-12]CNN_V0_72.hdf5\n",
      "1998/1998 [==============================] - 12190s 6s/step - loss: 0.6938 - binary_accuracy: 0.9291 - val_loss: 0.6931 - val_binary_accuracy: 0.9299\n",
      "Epoch 2/2\n",
      "1998/1998 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.9299\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.92985\n",
      "1998/1998 [==============================] - 13132s 7s/step - loss: 0.6931 - binary_accuracy: 0.9299 - val_loss: 0.6931 - val_binary_accuracy: 0.9299\n"
     ]
    }
   ],
   "source": [
    "###### Save model\n",
    "model_ckpt_path = f\"[{bert_model_name}]{model_name}_V{model_ver}_{max_seq_len}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(model_ckpt_path, monitor='val_binary_accuracy', mode='max',verbose=1, save_best_only=True, save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Training\n",
    "print(f\"Training model with {bert_model_name}_{model_name}_V{model_ver}_{max_seq_len}\\n\")\n",
    "train_history = model.fit(data.train_x, data.train_y, validation_data=(data.val_x,data.val_y), epochs=2, batch_size=16, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T09:44:14.858973Z",
     "iopub.status.busy": "2021-08-10T09:44:14.858678Z",
     "iopub.status.idle": "2021-08-10T09:44:15.247014Z",
     "shell.execute_reply": "2021-08-10T09:44:15.246050Z",
     "shell.execute_reply.started": "2021-08-10T09:44:14.858942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2558dfb48b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy and loss\n",
    "history_dict = train_history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T09:44:15.248710Z",
     "iopub.status.busy": "2021-08-10T09:44:15.248372Z",
     "iopub.status.idle": "2021-08-10T09:44:15.259665Z",
     "shell.execute_reply": "2021-08-10T09:44:15.258749Z",
     "shell.execute_reply.started": "2021-08-10T09:44:15.248672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save architecture model\n",
    "config = model.to_json()\n",
    "model_config_path = f\"[{bert_model_name}]{model_name}_V{model_ver}_{max_seq_len}.json\"\n",
    "with open(model_config_path, \"w\") as outfile:\n",
    "    json.dump(config, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T09:44:15.261482Z",
     "iopub.status.busy": "2021-08-10T09:44:15.261015Z",
     "iopub.status.idle": "2021-08-10T09:47:08.403074Z",
     "shell.execute_reply": "2021-08-10T09:47:08.402123Z",
     "shell.execute_reply.started": "2021-08-10T09:44:15.261436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY_SCORE:  0.9299\n",
      "F1_SCORE:  0.4818\n",
      "ROC_AUC_SCORE:  0.5073\n",
      "CONFUSION_MATRIX:\n",
      " [[29720     0]\n",
      " [ 2242     0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_ckpt_path)\n",
    "y_pred_proba = model.predict(data.test_x)\n",
    "get_metrics(data.test_y, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + GCN with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 196 BERT weights from: ./bert_model.ckpt into <bert.model.BertModelLayer object at 0x0000025596147EE0> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 72)]              0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 72, 768)           108890112 \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 72, 32)            102528    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 108,993,321\n",
      "Trainable params: 108,993,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"LSTM\"\n",
    "model_ver = 0\n",
    "LR = 2e-5\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = Adam(learning_rate=LR)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "model = create_model(model_name, model_ver, max_seq_len, bert_checkpnt_file)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with uncased_L-12_H-768_A-12_LSTM_V0_72\n",
      "\n",
      "Epoch 1/3\n",
      "1998/1998 [==============================] - ETA: 0s - loss: 0.7187 - binary_accuracy: 0.9290 \n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.92985, saving model to [uncased_L-12_H-768_A-12]LSTM_V0_72.hdf5\n",
      "1998/1998 [==============================] - 56157s 28s/step - loss: 0.7187 - binary_accuracy: 0.9290 - val_loss: 0.6954 - val_binary_accuracy: 0.9299\n",
      "Epoch 2/3\n",
      " 855/1998 [===========>..................] - ETA: 8:28:00 - loss: 0.7080 - binary_accuracy: 0.9296"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_ckpt_path = f\"[{bert_model_name}]{model_name}_V{model_ver}_{max_seq_len}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(model_ckpt_path, monitor='val_binary_accuracy', mode='max',verbose=1, save_best_only=True, save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Training\n",
    "print(f\"Training model with {bert_model_name}_{model_name}_V{model_ver}_{max_seq_len}\\n\")\n",
    "train_history = model.fit(data.train_x, data.train_y, validation_data=(data.val_x,data.val_y), epochs=3, batch_size=16, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss\n",
    "history_dict = train_history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for model evaluation and algorithms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import collections\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#dl libraraies\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization,Reshape,Dot,Concatenate,Add,Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import cv2\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# specifically for deeplearning.\n",
    "from tensorflow.keras.layers import Dropout, Flatten,Activation,Input,Embedding\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataframe\n",
    "df=pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters which will be used throughout\n",
    "num_words = 15000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "val_size = 1000  # Size of the validation set\n",
    "epochs = 20  # Number of epochs we usually start to train with\n",
    "batch_size = 512  # Size of the batches used in the mini-batch gradient descent\n",
    "#Taking only two columns since it's a sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets conssits of every document as an array of tokenized words which are later appended to docs \n",
    "tweets=[word_tokenize(tweet) for tweet in df['tweet']]\n",
    "docs=[]\n",
    "for j in range(0,len(tweets)):\n",
    "    docs.append(tweets[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stops included both the stopwords and punctuations\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "not_list = [\"n't\", \"not\", \"no\"]\n",
    "stops.update(punctuations)\n",
    "stops.update(not_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the simple pos(part of speech) tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the pos tag for a word\n",
    "from nltk import pos_tag\n",
    "# now we are going to clean our data \n",
    "# we will remove stopwords and punctuations and lemmatize each document\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def clean(words):\n",
    "    output=[]\n",
    "    for word in words:\n",
    "        if word.lower() not in stops or word.lower() in not_list:\n",
    "            pos=pos_tag(word)\n",
    "            clean_word=lemmatizer.lemmatize(word,pos=get_simple_pos(pos[0][1]))\n",
    "            output.append(clean_word.lower())\n",
    "    str1=\" \".join(output).encode('utf-8')        \n",
    "    return str1\n",
    "#docs=[ clean(doc) for doc in docs]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['tweet','label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking variables to be used for train test split as X,y\n",
    "X,Y=df['tweet'].values,pd.get_dummies(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tokenizers to create the tokens having no of words=15000(num_words)\n",
    "tk = Tokenizer(num_words=num_words,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "#Complete data is tokenized to vectors and padding is done using zeros to match its length to the largest text in the dataset.\n",
    "tk.fit_on_texts(X)\n",
    "X = tk.texts_to_sequences(X)\n",
    "X = pad_sequences(X)\n",
    "#print(X[:2])\n",
    "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
    "print('{} words in dictionary'.format(tk.num_words))\n",
    "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tk,open('transform2.pkl','wb'))\n",
    "#files.download('transform2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
    "print('# Train data samples:', X_train.shape)\n",
    "print('# Test data samples:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting validation data as a part of training data\n",
    "X_train_rest, X_valid, Y_train_rest, Y_valid = train_test_split(X_train,Y_train, test_size=0.1, random_state=37)\n",
    "print('Shape of validation set:',X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function defined to test the models in the test set\n",
    "def test_model(model, epoch_stop):\n",
    "    model.fit(X_test\n",
    "              , Y_test\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=batch_size\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128 #dimension of the word embedding vector for each word in a sequence \n",
    "lstm_out = 196  #no of lstm layers\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(num_words, embed_dim,input_length = X_train.shape[1]))\n",
    "#Adding dropout\n",
    "lstm_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "#Adding a regularized dense layer\n",
    "lstm_model.add(layers.Dense(32,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "lstm_model.add(layers.Dropout(0.5))\n",
    "lstm_model.add(Dense(2,activation='softmax'))\n",
    "lstm_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model trained on the training data and taking validation data into account to avoid overfitting for 4 epochs \n",
    "history_LSTM=lstm_model.fit(X_train_rest, Y_train_rest, epochs = 20, batch_size=batch_size,validation_data=(X_valid, Y_valid),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=history_LSTM\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction by our lstm model on the test dataset\n",
    "lstm_results = test_model(lstm_model, 3)\n",
    "print('/n')\n",
    "print('Test accuracy of lstm model: {0:.2f}%'.format(lstm_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU, Dense, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(num_words, embed_dim,input_length = X_train.shape[1]))\n",
    "gru_model.add(GRU(128, return_sequences=False))\n",
    "gru_model.add(Dropout(0.5))\n",
    "gru_model.add(Dense(2, activation = 'sigmoid'))\n",
    "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(gru_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model trained on the training data and taking validation data into account to avoid overfitting for 4 epochs \n",
    "history_GRU=gru_model.fit(X_train_rest, Y_train_rest, epochs = 20, batch_size=batch_size,validation_data=(X_valid, Y_valid),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=history_GRU\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction by our lstm model on the test dataset\n",
    "gru_results = test_model(gru_model, 3)\n",
    "print('/n')\n",
    "print('Test accuracy of gru model: {0:.2f}%'.format(gru_results[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = df.label.nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "\n",
    "    text = re.sub(r'http\\S+', \" \", text)    # remove urls\n",
    "    text = re.sub(r'@\\w+',' ',text)         # remove mentions\n",
    "    text = re.sub(r'#\\w+', ' ', text)       # remove hastags\n",
    "    text = re.sub('r<.*?>',' ', text)       # remove html tags\n",
    "    \n",
    "    # remove stopwords \n",
    "    text = text.split()\n",
    "    text = \" \".join([word for word in text if not word in stop_words])\n",
    "\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: cleaning_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sentence length\n",
    "max_len_words = max(list(df['tweet'].apply(len)))\n",
    "print(max_len_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x_train, y_train, max_len_word):\n",
    "    # because the data distribution is imbalanced, \"stratify\" is used\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "                                                      test_size=.2, shuffle=True, \n",
    "                                                      stratify=y_train, random_state=0)\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequence_dict = tokenizer.word_index\n",
    "    word_dict = dict((num, val) for (val, num) in sequence_dict.items())\n",
    "\n",
    "    # Sequence data\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    train_padded = pad_sequences(train_sequences,\n",
    "                                 maxlen=max_len_word,\n",
    "                                 truncating='post',\n",
    "                                 padding='post')\n",
    "    \n",
    "    val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "    val_padded = pad_sequences(val_sequences,\n",
    "                                maxlen=max_len_word,\n",
    "                                truncating='post',\n",
    "                                padding='post', )\n",
    "    \n",
    "    print(train_padded.shape)\n",
    "    print(val_padded.shape)\n",
    "    print('Total words: {}'.format(len(word_dict)))\n",
    "    return train_padded, val_padded, y_train, y_val, word_dict\n",
    "\n",
    "X_train, X_val, y_train, y_val, word_dict = tokenizer(df.tweet, df.label, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = Sequential([\n",
    "    layers.Embedding(5000, 100, input_length=100),\n",
    "    layers.SimpleRNN(64, return_sequences=True, recurrent_dropout=0.4),\n",
    "    layers.GlobalAveragePooling1D(),    # or layers.Flatten()\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = model.fit(X_train, y_train,\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['accuracy'])\n",
    "plt.plot(trained.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['loss'])\n",
    "plt.plot(trained.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "def build_cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(5000, 100, input_length=100))\n",
    "\n",
    "\n",
    "    model.add(Conv1D(64, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    #model.add(MaxPooling1D(2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=1024,activation=\"relu\"))\n",
    "    model.add(Dense(units=512,activation=\"relu\"))\n",
    "    \n",
    "    model.add(Dense(units=num_classes,activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = Adam(lr=0.000055,beta_1=0.9,beta_2=0.999)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,metrics=[\"accuracy\"],loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_history = cnn_model.fit(X_train, y_train,\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_history.history['accuracy'])\n",
    "plt.plot(cnn_history.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_history.history['loss'])\n",
    "plt.plot(cnn_history.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['label'] = df['Text Label'].map({'Non-Bullying': 0, 'Bullying': 1})\n",
    "df['message'] = df['tweet']\n",
    "#df.drop(['Text Label','Tweet'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X) # Fit the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticR = LogisticRegression()\n",
    "LogisticR.fit(X_train, y_train) \n",
    "y_pred = LogisticR.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "LR = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForest = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "RandomForest.fit(X_train, y_train) \n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "RF = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred = KNN.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "KNNA = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTree = DecisionTreeClassifier()\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "y_pred = DecisionTree.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "DT = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "svm = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = RandomForestClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(ensemble)\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E= accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b9bf3d753fefe854781e52229fcc2b6d37fd5cec0eed166290fc2ac2cd3389d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
